{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/circuit-finder/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspace/circuit-finder\")\n",
    "\n",
    "import torch\n",
    "\n",
    "from functools import partial\n",
    "from circuit_finder.data_loader import load_datasets_from_json\n",
    "from circuit_finder.pretrained import load_model\n",
    "from circuit_finder.experiments.run_dataset_sweep import ALL_DATASETS\n",
    "from circuit_finder.metrics import batch_avg_answer_diff\n",
    "from circuit_finder.constants import ProjectDir\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "\n",
    "def logit_diff(model, tokens, batch):\n",
    "    # Get the last-token logits\n",
    "    logits = model(tokens)[:, -1, :]\n",
    "    logit_diff = batch_avg_answer_diff(logits, batch)\n",
    "    return logit_diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: datasets/gender_bias.json\n",
      "Clean tokens: torch.Size([1, 6])\n",
      "Corrupt tokens: torch.Size([1, 6])\n",
      "Clean metric: 1.8746223449707031\n",
      "Corrupt metric: -3.3825511932373047\n",
      "\n",
      "Dataset: datasets/greaterthan_gpt2-small_prompts.json\n",
      "Clean tokens: torch.Size([1, 11])\n",
      "Corrupt tokens: torch.Size([1, 11])\n",
      "Clean metric: 3.544696807861328\n",
      "Corrupt metric: -1.5264644622802734\n",
      "\n",
      "Dataset: datasets/subject_verb_agreement.json\n",
      "Clean tokens: torch.Size([1, 8])\n",
      "Corrupt tokens: torch.Size([1, 8])\n",
      "Clean metric: 2.7700538635253906\n",
      "Corrupt metric: -3.5251340866088867\n",
      "\n",
      "Dataset: datasets/ioi/ioi_ABBA_template_0_prompts.json\n",
      "Clean tokens: torch.Size([1, 16])\n",
      "Corrupt tokens: torch.Size([1, 16])\n",
      "Clean metric: 4.267217636108398\n",
      "Corrupt metric: 1.609701156616211\n",
      "\n",
      "Dataset: datasets/ioi/ioi_ABBA_template_1_prompts.json\n",
      "Clean tokens: torch.Size([1, 20])\n",
      "Corrupt tokens: torch.Size([1, 20])\n",
      "Clean metric: 4.107460021972656\n",
      "Corrupt metric: 1.4901819229125977\n",
      "\n",
      "Dataset: datasets/ioi/ioi_BABA_template_0_prompts.json\n",
      "Clean tokens: torch.Size([1, 16])\n",
      "Corrupt tokens: torch.Size([1, 16])\n",
      "Clean metric: 1.0124521255493164\n",
      "Corrupt metric: 1.609701156616211\n",
      "\n",
      "Dataset: datasets/ioi/ioi_BABA_template_1_prompts.json\n",
      "Clean tokens: torch.Size([1, 20])\n",
      "Corrupt tokens: torch.Size([1, 20])\n",
      "Clean metric: 2.0608510971069336\n",
      "Corrupt metric: 1.4901819229125977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_path in ALL_DATASETS:\n",
    "    train_loader, _ = load_datasets_from_json(\n",
    "        model, ProjectDir / dataset_path, torch.device(\"cuda\"),\n",
    "        batch_size = 1\n",
    "    )\n",
    "    batch = next(iter(train_loader))\n",
    "    metric_fn = partial(logit_diff, batch=batch)\n",
    "    clean_metric = metric_fn(model, batch.clean)\n",
    "    corrupt_metric = metric_fn(model, batch.corrupt)\n",
    "    print(f\"Dataset: {dataset_path}\")\n",
    "    print(f\"Clean tokens: {batch.clean.shape}\")\n",
    "    print(f\"Corrupt tokens: {batch.corrupt.shape}\")\n",
    "    print(f\"Clean metric: {clean_metric}\")\n",
    "    print(f\"Corrupt metric: {corrupt_metric}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
