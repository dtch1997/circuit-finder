{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/home/daniel/ml_workspace/circuit-finder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/ml_workspace/circuit-finder/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from circuit_finder.pretrained import load_model\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee9dbcdeac34ad4a013e899de57c7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 26 files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from circuit_finder.pretrained import load_attn_saes, load_hooked_mlp_transcoders\n",
    "from circuit_finder.patching.indirect_leap import preprocess_attn_saes\n",
    "\n",
    "attn_sae_dict = load_attn_saes()\n",
    "attn_sae_dict = preprocess_attn_saes(attn_sae_dict, model)\n",
    "hooked_mlp_transcoder_dict = load_hooked_mlp_transcoders()\n",
    "\n",
    "attn_saes = list(attn_sae_dict.values())\n",
    "transcoders = list(hooked_mlp_transcoder_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_profession = \"doctor\"\n",
    "female_profession = \"nurse\"\n",
    "\n",
    "clean_text = f\"The {male_profession} is ready, you can go see\"\n",
    "answer = \" him\"\n",
    "wrong_answer = \" her\"\n",
    "corrupt_text = f\"The {female_profession} is ready, you can go see\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "clean_tokens = model.to_tokens(clean_text)\n",
    "answer_tokens = model.to_tokens(answer, prepend_bos=False).squeeze(-1)\n",
    "wrong_answer_tokens = model.to_tokens(wrong_answer, prepend_bos=False).squeeze(-1)\n",
    "corrupt_tokens = model.to_tokens(corrupt_text)\n",
    "\n",
    "print(clean_tokens.shape)\n",
    "print(answer_tokens.shape)\n",
    "print(corrupt_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'The', ' doctor', ' is', ' ready', ',', ' you', ' can', ' go', ' see']\n",
      "Tokenized answer: [' him']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.83</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36.58</span><span style=\"font-weight: bold\">% Token: | him|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m15.83\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m36.58\u001b[0m\u001b[1m% Token: | him|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 15.83 Prob: 36.58% Token: | him|\n",
      "Top 1th token. Logit: 15.08 Prob: 17.31% Token: | her|\n",
      "Top 2th token. Logit: 14.11 Prob:  6.60% Token: | the|\n",
      "Top 3th token. Logit: 13.83 Prob:  4.96% Token: | your|\n",
      "Top 4th token. Logit: 13.48 Prob:  3.48% Token: | it|\n",
      "Top 5th token. Logit: 13.13 Prob:  2.46% Token: | if|\n",
      "Top 6th token. Logit: 13.04 Prob:  2.26% Token: |.|\n",
      "Top 7th token. Logit: 12.87 Prob:  1.91% Token: | a|\n",
      "Top 8th token. Logit: 12.80 Prob:  1.77% Token: | his|\n",
      "Top 9th token. Logit: 12.58 Prob:  1.43% Token: | what|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' him'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' him'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'The', ' nurse', ' is', ' ready', ',', ' you', ' can', ' go', ' see']\n",
      "Tokenized answer: [' her']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.20</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.15</span><span style=\"font-weight: bold\">% Token: | her|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.20\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m50.15\u001b[0m\u001b[1m% Token: | her|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.20 Prob: 50.15% Token: | her|\n",
      "Top 1th token. Logit: 14.17 Prob:  6.61% Token: | the|\n",
      "Top 2th token. Logit: 13.78 Prob:  4.47% Token: | if|\n",
      "Top 3th token. Logit: 13.55 Prob:  3.57% Token: | it|\n",
      "Top 4th token. Logit: 13.40 Prob:  3.07% Token: | what|\n",
      "Top 5th token. Logit: 13.28 Prob:  2.71% Token: | your|\n",
      "Top 6th token. Logit: 13.15 Prob:  2.39% Token: | him|\n",
      "Top 7th token. Logit: 13.13 Prob:  2.33% Token: |.|\n",
      "Top 8th token. Logit: 12.95 Prob:  1.95% Token: | for|\n",
      "Top 9th token. Logit: 12.63 Prob:  1.42% Token: | a|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' her'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' her'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens import utils \n",
    "\n",
    "utils.test_prompt(clean_text, answer, model)\n",
    "utils.test_prompt(corrupt_text, wrong_answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_finder.utils import clear_memory\n",
    "\n",
    "if 'leap' in globals():\n",
    "    del leap\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7484092712402344\n",
      "-2.2224950790405273\n",
      "-1.7874259948730469\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from eindex import eindex\n",
    "from circuit_finder.patching.eap_graph import EAPGraph\n",
    "from circuit_finder.patching.ablate import get_metric_with_ablation\n",
    "from circuit_finder.patching.indirect_leap import IndirectLEAP, LEAPConfig\n",
    "from circuit_finder.utils import clear_memory\n",
    "\n",
    "ablate_tokens = corrupt_tokens\n",
    "\n",
    "def compute_logit_diff(model, clean_tokens, answer_tokens, wrong_answer_tokens):\n",
    "    clean_logits = model(clean_tokens)\n",
    "    last_logits = clean_logits[:, -1, :]\n",
    "    correct_logits = eindex(last_logits, answer_tokens, \"batch [batch]\")\n",
    "    wrong_logits = eindex(last_logits, wrong_answer_tokens, \"batch [batch]\")\n",
    "    return correct_logits - wrong_logits\n",
    "\n",
    "def metric_fn(model, tokens):\n",
    "    logit_diff = compute_logit_diff(model, tokens, answer_tokens, wrong_answer_tokens)\n",
    "    return logit_diff.mean()\n",
    "\n",
    "# NOTE: First, get the ceiling of the patching metric.\n",
    "# TODO: Replace 'last_token_logit' with logit difference\n",
    "with torch.no_grad():\n",
    "    ceiling = metric_fn(model, clean_tokens).item()\n",
    "print(ceiling)\n",
    "\n",
    "# NOTE: Second, get floor of patching metric using empty graph, i.e. ablate everything\n",
    "with torch.no_grad():\n",
    "    empty_graph = EAPGraph([])\n",
    "    floor = get_metric_with_ablation(\n",
    "        model,\n",
    "        empty_graph,\n",
    "        clean_tokens,\n",
    "        metric_fn,\n",
    "        hooked_mlp_transcoder_dict,\n",
    "        attn_sae_dict,\n",
    "        ablate_nodes=\"bm\",\n",
    "        ablate_errors=False,  # Do not ablate errors when running forward pass\n",
    "        first_ablated_layer=2,\n",
    "        corrupt_tokens = ablate_tokens,\n",
    "    ).item()\n",
    "clear_memory()\n",
    "print(floor)\n",
    "\n",
    "\n",
    "# now sweep over thresholds to get graphs with variety of numbers of nodes\n",
    "# for each graph we calculate faithfulness\n",
    "num_nodes_list = []\n",
    "metrics_list = []\n",
    "\n",
    "# Sweep over thresholds\n",
    "# TODO: make configurable\n",
    "# thresholds = [0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1.0]\n",
    "thresholds = [0.001]\n",
    "for threshold in thresholds:\n",
    "    # Setup LEAP algorithm\n",
    "    model.reset_hooks()\n",
    "    cfg = LEAPConfig(threshold=threshold,\n",
    "                    contrast_pairs=True, \n",
    "                    qk_enabled=True,\n",
    "                    chained_attribs=True,\n",
    "                    abs_attribs = False,\n",
    "                    store_error_attribs=True)\n",
    "    leap = IndirectLEAP(\n",
    "        cfg=cfg,\n",
    "        tokens=clean_tokens,\n",
    "        model=model,\n",
    "        metric=metric_fn,\n",
    "        attn_saes=attn_saes,  # type: ignore\n",
    "        transcoders=transcoders,\n",
    "        corrupt_tokens=ablate_tokens,\n",
    "    )\n",
    "\n",
    "    # Populate the graph\n",
    "    leap.run()\n",
    "\n",
    "    # Save the graph\n",
    "    graph = EAPGraph(leap.graph)\n",
    "    error_graph = EAPGraph(leap.error_graph)\n",
    "    num_nodes = len(graph.get_src_nodes())\n",
    "\n",
    "    # # Calculate the metric under ablation\n",
    "    with torch.no_grad():\n",
    "        metric = get_metric_with_ablation(\n",
    "            model,\n",
    "            graph,\n",
    "            clean_tokens,\n",
    "            metric_fn,\n",
    "            hooked_mlp_transcoder_dict,\n",
    "            attn_sae_dict,\n",
    "            ablate_nodes=\"bm\",\n",
    "            ablate_errors=False,\n",
    "            first_ablated_layer=2,\n",
    "            corrupt_tokens = ablate_tokens,\n",
    "        ).item()\n",
    "    clear_memory()\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'The', ' doctor', ' is', ' ready', ',', ' you', ' can', ' go', ' see'] ['<|endoftext|>', 'The', ' nurse', ' is', ' ready', ',', ' you', ' can', ' go', ' see']\n",
      "graph.html\n",
      "Generated graph.html. Open this file in Live Server to view the graph.\n"
     ]
    }
   ],
   "source": [
    "from circuit_finder.plotting import make_html_graph\n",
    "\n",
    "# print(len(graph.get_edges()))\n",
    "make_html_graph(leap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'leap' in globals():\n",
    "    del leap\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4863</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021989</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>0.021989</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>11891</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20543</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022519</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.022519</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>23862</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9645</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009077</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>-0.009077</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  src_module_name  src_layer  src_token_idx  src_feature_idx dest_module_name  \\\n",
       "0             mlp          0              9             4863           metric   \n",
       "1             mlp          0              9            11891           metric   \n",
       "2             mlp          0              9            20543           metric   \n",
       "3             mlp          0              9            23862           metric   \n",
       "4             mlp          1              9             9645           metric   \n",
       "\n",
       "   dest_layer  dest_token_idx  dest_feature_idx  edge_metric_attr  \\\n",
       "0          12               9                 0          0.021989   \n",
       "1          12               9                 0          0.009094   \n",
       "2          12               9                 0          0.022519   \n",
       "3          12               9                 0          0.025424   \n",
       "4          12               9                 0         -0.009077   \n",
       "\n",
       "   edge_metric_grad  node_node_attr  node_node_grad edge_type  \n",
       "0          0.003526        0.021989        0.003526      None  \n",
       "1          0.002660        0.009094        0.002660      None  \n",
       "2          0.001831        0.022519        0.001831      None  \n",
       "3          0.004463        0.025424        0.004463      None  \n",
       "4          0.002790       -0.009077        0.002790      None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the graph to a dataframe\n",
    "\n",
    "import pandas as pd \n",
    "from circuit_finder.core.types import parse_node_name\n",
    "\n",
    "rows = []\n",
    "for edge, edge_info, edge_type in graph.graph:\n",
    "    (dest, src) = edge\n",
    "    if dest == \"null\": continue\n",
    "    (node_node_attr, node_node_grad, edge_metric_attr, edge_metric_grad) = edge_info\n",
    "\n",
    "    src_module_name, src_layer, src_token_idx, src_feature_idx = parse_node_name(src)    \n",
    "    dest_module_name, dest_layer, dest_token_idx, dest_feature_idx = parse_node_name(dest)\n",
    "\n",
    "    rows.append({\n",
    "        \"src_module_name\": src_module_name,\n",
    "        \"src_layer\": src_layer,\n",
    "        \"src_token_idx\": src_token_idx,\n",
    "        \"src_feature_idx\": src_feature_idx,\n",
    "        \"dest_module_name\": dest_module_name,\n",
    "        \"dest_layer\": dest_layer,\n",
    "        \"dest_token_idx\": dest_token_idx,\n",
    "        \"dest_feature_idx\": dest_feature_idx,\n",
    "        \"edge_metric_attr\": edge_metric_attr,\n",
    "        \"edge_metric_grad\": edge_metric_grad,\n",
    "        \"node_node_attr\": node_node_attr,\n",
    "        \"node_node_grad\": node_node_grad,\n",
    "        \"edge_type\": edge_type\n",
    "    }) \n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Attribution \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from circuit_finder.patching.ablate import splice_model_with_saes_and_transcoders\n",
    "from circuit_finder.patching.gradient_cache import get_gradient_cache\n",
    "\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    grad_cache = get_gradient_cache(spliced_model, clean_tokens, metric_fn)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, clean_cache = model.run_with_cache(clean_tokens)\n",
    "        _, corrupt_cache = model.run_with_cache(corrupt_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute node attributions\n",
    "attr_cache = {}\n",
    "for node, grad in grad_cache.items():\n",
    "    # NOTE on sign: \n",
    "    # clean - corr --> positive attrib means metric(clean) is higher than metric(corr). \n",
    "    attr_cache[node] = grad * (clean_cache[node] - corrupt_cache[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589824\n"
     ]
    }
   ],
   "source": [
    "# Get the features with high attribution \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "attn_act_names = [\n",
    "    f\"blocks.{layer}.attn.hook_z.hook_sae_acts_post\" for layer in range(model.cfg.n_layers)\n",
    "]\n",
    "\n",
    "transcoder_act_names = [\n",
    "    f\"blocks.{layer}.mlp.transcoder.hook_sae_acts_post\" for layer in range(model.cfg.n_layers)\n",
    "]\n",
    "\n",
    "all_act_names = attn_act_names + transcoder_act_names\n",
    "\n",
    "\n",
    "def get_node_attrib_df():\n",
    "    dfs = []\n",
    "    for act_name in all_act_names:\n",
    "        node_attrib = attr_cache[act_name]\n",
    "        feature_idx = list(range(node_attrib.shape[-1]))\n",
    "        total_node_attrib = node_attrib.sum(0).sum(0).tolist()\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            \"feature_idx\": feature_idx,\n",
    "            \"total_node_attrib\": total_node_attrib,\n",
    "        })\n",
    "        df['act_name'] = act_name\n",
    "        df['layer'] = int(act_name.split('.')[1])\n",
    "        df['module_name'] = act_name.split('.')[2]\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    print(len(df))\n",
    "    df.head()\n",
    "\n",
    "node_attrib_df = get_node_attrib_df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outgoing_edge_df(\n",
    "    df: pd.DataFrame, \n",
    "    src_module_name: str,\n",
    "    src_layer: int,\n",
    "    src_feature_idx: int,\n",
    "):\n",
    "    return df[\n",
    "        (df[\"src_module_name\"] == src_module_name)\n",
    "        & (df[\"src_layer\"] == src_layer)\n",
    "        & (df[\"src_feature_idx\"] == src_feature_idx)\n",
    "    ]\n",
    "\n",
    "def get_incoming_edge_df(\n",
    "    df: pd.DataFrame, \n",
    "    dest_module_name: str,\n",
    "    dest_layer: int,\n",
    "    dest_feature_idx: int,\n",
    "):\n",
    "    return df[\n",
    "        (df[\"dest_module_name\"] == dest_module_name)\n",
    "        & (df[\"dest_layer\"] == dest_layer)\n",
    "        & (df[\"dest_feature_idx\"] == dest_feature_idx)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some utilities for patching a single node\n",
    "\n",
    "from transformer_lens import ActivationCache\n",
    "from circuit_finder.core.types import Node, parse_node_name\n",
    "\n",
    "def get_act_name(module_name, layer):\n",
    "    if module_name == \"attn\":\n",
    "        return f\"blocks.{layer}.attn.hook_z.hook_sae_acts_post\"\n",
    "    elif module_name == \"mlp\":\n",
    "        return f\"blocks.{layer}.mlp.transcoder.hook_sae_acts_post\"\n",
    "    else:\n",
    "        raise ValueError(module_name)\n",
    "\n",
    "def get_node_act(\n",
    "    cache: ActivationCache,\n",
    "    module_name, layer, token_idx, feature_idx\n",
    "):\n",
    "    act_name = get_act_name(module_name, layer)\n",
    "    return cache[act_name][:, token_idx, feature_idx]\n",
    "\n",
    "def node_patch_hook(act, hook, token_idx, feature_idx, value):\n",
    "    \"\"\" Patches a node by setting its activation to a fixed value. \"\"\"\n",
    "    act[:, token_idx, feature_idx] = value\n",
    "    return act\n",
    "\n",
    "def get_node_patch_hook(\n",
    "    node: Node,\n",
    "    value: float\n",
    "):\n",
    "\n",
    "    module_name, layer, token_idx, feature_idx = parse_node_name(node)\n",
    "    hook_name = get_act_name(module_name, layer)\n",
    "\n",
    "    def hook_fn(act, hook):\n",
    "        return node_patch_hook(act, hook, token_idx, feature_idx, value)\n",
    "    \n",
    "    return hook_name, hook_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_finder.core.types import get_node_name, parse_node_name\n",
    "\n",
    "nodes = {\n",
    "    \"doctor_detector\": get_node_name(\"mlp\", 1, 2, 10644),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doctor Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the outgoing edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>22510</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.067385</td>\n",
       "      <td>0.577717</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13188</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.095022</td>\n",
       "      <td>0.814663</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19883</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.115886</td>\n",
       "      <td>0.993540</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7611</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>0.042722</td>\n",
       "      <td>0.366278</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5922</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.090604</td>\n",
       "      <td>0.776791</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>17446</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.054334</td>\n",
       "      <td>0.465831</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15503</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.061043</td>\n",
       "      <td>0.523348</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>19969</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.041476</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>18618</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.044099</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>919</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.123412</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>17982</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.066559</td>\n",
       "      <td>0.570644</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22511</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.026511</td>\n",
       "      <td>0.227290</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>19048</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.033574</td>\n",
       "      <td>0.287842</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>19969</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.025616</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>14709</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.033895</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4341</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.103902</td>\n",
       "      <td>0.890798</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>mlp</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6101</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.039213</td>\n",
       "      <td>0.336192</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9826</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>0.048512</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5993</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.089128</td>\n",
       "      <td>0.764133</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4014</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>0.078054</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>18201</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.023004</td>\n",
       "      <td>0.197225</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9836</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.017440</td>\n",
       "      <td>0.149518</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10644</td>\n",
       "      <td>attn</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11453</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.114436</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    src_module_name  src_layer  src_token_idx  src_feature_idx  \\\n",
       "234             mlp          1              2            10644   \n",
       "285             mlp          1              2            10644   \n",
       "331             mlp          1              2            10644   \n",
       "243             mlp          1              2            10644   \n",
       "302             mlp          1              2            10644   \n",
       "307             mlp          1              2            10644   \n",
       "281             mlp          1              2            10644   \n",
       "147             mlp          1              2            10644   \n",
       "223             mlp          1              2            10644   \n",
       "220             mlp          1              2            10644   \n",
       "252             mlp          1              2            10644   \n",
       "312             mlp          1              2            10644   \n",
       "256             mlp          1              2            10644   \n",
       "187             mlp          1              2            10644   \n",
       "142             mlp          1              2            10644   \n",
       "259             mlp          1              2            10644   \n",
       "201             mlp          1              2            10644   \n",
       "140             mlp          1              2            10644   \n",
       "339             mlp          1              2            10644   \n",
       "212             mlp          1              2            10644   \n",
       "328             mlp          1              2            10644   \n",
       "222             mlp          1              2            10644   \n",
       "208             mlp          1              2            10644   \n",
       "\n",
       "    dest_module_name  dest_layer  dest_token_idx  dest_feature_idx  \\\n",
       "234              mlp           7               2             22510   \n",
       "285              mlp           6               2             13188   \n",
       "331              mlp           3               2             19883   \n",
       "243              mlp           7               2              7611   \n",
       "302              mlp           5               2              5922   \n",
       "307              mlp           5               2             17446   \n",
       "281              mlp           6               2             15503   \n",
       "147             attn          10               9             19969   \n",
       "223             attn           8               9             18618   \n",
       "220             attn           8               9               919   \n",
       "252              mlp           7               2             17982   \n",
       "312              mlp           5               2             22511   \n",
       "256              mlp           7               2             19048   \n",
       "187             attn          10               9             19969   \n",
       "142             attn          10               9             14709   \n",
       "259              mlp           7               2              4341   \n",
       "201              mlp           9               2              6101   \n",
       "140             attn          10               9              9826   \n",
       "339             attn           2               3              5993   \n",
       "212             attn           9               9              4014   \n",
       "328             attn           4               3             18201   \n",
       "222             attn           8               3              9836   \n",
       "208             attn           9               9             11453   \n",
       "\n",
       "     edge_metric_attr  edge_metric_grad  node_node_attr  node_node_grad  \\\n",
       "234          0.001120          0.009598        0.067385        0.577717   \n",
       "285          0.000958          0.008213        0.095022        0.814663   \n",
       "331          0.000869          0.007447        0.115886        0.993540   \n",
       "243          0.000847          0.007260        0.042722        0.366278   \n",
       "302          0.000664          0.005693        0.090604        0.776791   \n",
       "307          0.000597          0.005118        0.054334        0.465831   \n",
       "281          0.000467          0.004004        0.061043        0.523348   \n",
       "147          0.000423          0.003630        0.004838        0.041476   \n",
       "223          0.000409          0.003509        0.005144        0.044099   \n",
       "220          0.000403          0.003452        0.014395        0.123412   \n",
       "252          0.000319          0.002737        0.066559        0.570644   \n",
       "312          0.000303          0.002595        0.026511        0.227290   \n",
       "256          0.000291          0.002495        0.033574        0.287842   \n",
       "187          0.000262          0.002242        0.002988        0.025616   \n",
       "142          0.000237          0.002035        0.003953        0.033895   \n",
       "259          0.000218          0.001872        0.103902        0.890798   \n",
       "201          0.000210          0.001805        0.039213        0.336192   \n",
       "140          0.000181          0.001556        0.005658        0.048512   \n",
       "339          0.000175          0.001498        0.089128        0.764133   \n",
       "212          0.000174          0.001491        0.009104        0.078054   \n",
       "328          0.000163          0.001400        0.023004        0.197225   \n",
       "222          0.000152          0.001302        0.017440        0.149518   \n",
       "208          0.000145          0.001243        0.013348        0.114436   \n",
       "\n",
       "    edge_type  \n",
       "234      None  \n",
       "285      None  \n",
       "331      None  \n",
       "243      None  \n",
       "302      None  \n",
       "307      None  \n",
       "281      None  \n",
       "147        ov  \n",
       "223        ov  \n",
       "220        ov  \n",
       "252      None  \n",
       "312      None  \n",
       "256      None  \n",
       "187         k  \n",
       "142        ov  \n",
       "259      None  \n",
       "201      None  \n",
       "140        ov  \n",
       "339        ov  \n",
       "212        ov  \n",
       "328        ov  \n",
       "222        ov  \n",
       "208        ov  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_name, layer, token_idx, feature_idx = parse_node_name(nodes[\"doctor_detector\"])\n",
    "get_outgoing_edge_df(df, module_name, layer, feature_idx).sort_values('edge_metric_attr', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node patching for L8.Att.14.16513\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    for value in range(11):\n",
    "        with model.hooks(fwd_hooks = [get_node_patch_hook(l8_att_node, value)]):\n",
    "            metric = metric_fn(model, clean_tokens).item()\n",
    "            print(value, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot cosine similarity to MLP weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n"
     ]
    }
   ],
   "source": [
    "from einops import repeat\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get the relevant weights\n",
    "W_dec = transcoders[1].W_dec\n",
    "mlp_W_out = model.blocks[1].mlp.W_out\n",
    "w_dec = W_dec[10644]\n",
    "w_dec_repeat = repeat(w_dec, 'f -> b f', b = mlp_W_\n",
    "print(w_dec_repeat.shape)\n",
    "print(mlp_W_out.shape)\n",
    "# Compute cosine similarity\n",
    "\n",
    "cosine_sim = F.cosine_similarity(w_dec, mlp_W_out, dim=-1)\n",
    "print(cosine_sim.shape)\n",
    "cosine_sim_np = cosine_sim.detach().cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cosine similarity between doctor detector W_dec and Layer 1 MLP W_out')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "sns.set_theme()\n",
    "sns.histplot(cosine_sim_np, bins=100)\n",
    "plt.title(\"Cosine similarity between doctor detector W_dec and Layer 1 MLP W_out\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Him\" Predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [src_module_name, src_layer, src_token_idx, src_feature_idx, dest_module_name, dest_layer, dest_token_idx, dest_feature_idx, edge_metric_attr, edge_metric_grad, node_node_attr, node_node_grad, edge_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upstream edges for layer 6 att 17410\n",
    "\n",
    "get_incoming_edge_df(df, \"attn\", 6, 17410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [src_module_name, src_layer, src_token_idx, src_feature_idx, dest_module_name, dest_layer, dest_token_idx, dest_feature_idx, edge_metric_attr, edge_metric_grad, node_node_attr, node_node_grad, edge_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downstream edges for layer 6 att 17410\n",
    "\n",
    "get_outgoing_edge_df(df, \"attn\", 6, 17410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [src_module_name, src_layer, src_token_idx, src_feature_idx, dest_module_name, dest_layer, dest_token_idx, dest_feature_idx, edge_metric_attr, edge_metric_grad, node_node_attr, node_node_grad, edge_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df = df[\n",
    "    (df[\"src_layer\"] == 8) \n",
    "    & (df[\"src_module_name\"] == \"attn\") \n",
    "    & (df[\"src_feature_idx\"] == 16513)\n",
    "]\n",
    "\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [src_module_name, src_layer, src_token_idx, src_feature_idx, dest_module_name, dest_layer, dest_token_idx, dest_feature_idx, edge_metric_attr, edge_metric_grad, node_node_attr, node_node_grad, edge_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df = df[\n",
    "    (df[\"src_layer\"] == 10) \n",
    "    & (df[\"src_module_name\"] == \"attn\") \n",
    "    & (df[\"src_feature_idx\"] == 3849)\n",
    "]\n",
    "\n",
    "node_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_finder.core.types import get_node_name\n",
    "\n",
    "l6_att_node = get_node_name(\"attn\", 6, 10, 17410)\n",
    "l8_att_node = get_node_name(\"attn\", 8, 14, 16513)\n",
    "l10_att_node = get_node_name(\"attn\", 10, 14, 3849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the clean and corrupt cache\n",
    "from circuit_finder.patching.ablate import splice_model_with_saes_and_transcoders\n",
    "\n",
    "def filter_sae_acts_and_errors(name: str):\n",
    "    return \"hook_sae_acts_post\" in name or \"hook_sae_error\" in name\n",
    "\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    _, clean_cache = model.run_with_cache(clean_tokens, names_filter = filter_sae_acts_and_errors)\n",
    "    _, corrupt_cache = model.run_with_cache(corrupt_tokens, names_filter = filter_sae_acts_and_errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for dimension 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m node_patch_hook(act, hook, token_idx, feature_idx, value)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hook_name, hook_fn\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_node_act\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m17410\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_node_act(corrupt_cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m17410\u001b[39m))\n",
      "Cell \u001b[0;32mIn[25], line 19\u001b[0m, in \u001b[0;36mget_node_act\u001b[0;34m(cache, module_name, layer, token_idx, feature_idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_node_act\u001b[39m(\n\u001b[1;32m     15\u001b[0m     cache: ActivationCache,\n\u001b[1;32m     16\u001b[0m     module_name, layer, token_idx, feature_idx\n\u001b[1;32m     17\u001b[0m ):\n\u001b[1;32m     18\u001b[0m     act_name \u001b[38;5;241m=\u001b[39m get_act_name(module_name, layer)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mact_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for dimension 1 with size 10"
     ]
    }
   ],
   "source": [
    "# Define some utilities for patching a single node\n",
    "\n",
    "from transformer_lens import ActivationCache\n",
    "from circuit_finder.core.types import Node, parse_node_name\n",
    "\n",
    "def get_act_name(module_name, layer):\n",
    "    if module_name == \"attn\":\n",
    "        return f\"blocks.{layer}.attn.hook_z.hook_sae_acts_post\"\n",
    "    elif module_name == \"mlp\":\n",
    "        return f\"blocks.{layer}.mlp.transcoder.hook_sae_acts_post\"\n",
    "    else:\n",
    "        raise ValueError(module_name)\n",
    "\n",
    "def get_node_act(\n",
    "    cache: ActivationCache,\n",
    "    module_name, layer, token_idx, feature_idx\n",
    "):\n",
    "    act_name = get_act_name(module_name, layer)\n",
    "    return cache[act_name][:, token_idx, feature_idx]\n",
    "\n",
    "def node_patch_hook(act, hook, token_idx, feature_idx, value):\n",
    "    \"\"\" Patches a node by setting its activation to a fixed value. \"\"\"\n",
    "    act[:, token_idx, feature_idx] = value\n",
    "    return act\n",
    "\n",
    "def get_node_patch_hook(\n",
    "    node: Node,\n",
    "    value: float\n",
    "):\n",
    "\n",
    "    module_name, layer, token_idx, feature_idx = parse_node_name(node)\n",
    "    hook_name = get_act_name(module_name, layer)\n",
    "\n",
    "    def hook_fn(act, hook):\n",
    "        return node_patch_hook(act, hook, token_idx, feature_idx, value)\n",
    "    \n",
    "    return hook_name, hook_fn\n",
    "\n",
    "print(get_node_act(clean_cache, \"attn\", 6, 10, 17410))\n",
    "print(get_node_act(corrupt_cache, \"attn\", 6, 10, 17410))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l6_att_feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) \u001b[38;5;28;01mas\u001b[39;00m spliced_model:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks \u001b[38;5;241m=\u001b[39m [get_node_patch_hook(\u001b[43ml6_att_feat\u001b[49m, value)]):\n\u001b[1;32m      5\u001b[0m             metric \u001b[38;5;241m=\u001b[39m metric_fn(model, clean_tokens)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;28mprint\u001b[39m(value, metric)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l6_att_feat' is not defined"
     ]
    }
   ],
   "source": [
    "# Node patching for L6.Att.10.17410\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    for value in range(11):\n",
    "        with model.hooks(fwd_hooks = [get_node_patch_hook(l6_att_feat, value)]):\n",
    "            metric = metric_fn(model, clean_tokens).item()\n",
    "            print(value, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.3522], device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "l8_att_node_info = parse_node_name(l8_att_node)\n",
    "print(get_node_act(clean_cache, *l8_att_node_info))\n",
    "print(get_node_act(corrupt_cache, *l8_att_node_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.6199398040771484\n",
      "1 2.6861095428466797\n",
      "2 2.7564697265625\n",
      "3 2.830913543701172\n",
      "4 2.9091930389404297\n",
      "5 2.990968704223633\n",
      "6 3.0757503509521484\n",
      "7 3.1629371643066406\n",
      "8 3.251924514770508\n",
      "9 3.3420658111572266\n",
      "10 3.432809829711914\n"
     ]
    }
   ],
   "source": [
    "# Node patching for L8.Att.14.16513\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    for value in range(11):\n",
    "        with model.hooks(fwd_hooks = [get_node_patch_hook(l8_att_node, value)]):\n",
    "            metric = metric_fn(model, clean_tokens).item()\n",
    "            print(value, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21.6992], device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "l10_att_node_info = parse_node_name(l10_att_node)\n",
    "print(get_node_act(clean_cache, *l10_att_node_info))\n",
    "print(get_node_act(corrupt_cache, *l10_att_node_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.545804977416992\n",
      "1 2.5825119018554688\n",
      "2 2.619386672973633\n",
      "3 2.6564464569091797\n",
      "4 2.6936283111572266\n",
      "5 2.730976104736328\n",
      "6 2.768484115600586\n",
      "7 2.8061351776123047\n",
      "8 2.843921661376953\n",
      "9 2.8818435668945312\n",
      "10 2.9199295043945312\n"
     ]
    }
   ],
   "source": [
    "# Node patching for L10.Att.14.16513\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    for value in range(11):\n",
    "        with model.hooks(fwd_hooks = [get_node_patch_hook(l10_att_node, value)]):\n",
    "            metric = metric_fn(model, clean_tokens).item()\n",
    "            print(value, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2.9199295043945312\n",
      "Tokenized prompt: ['<|endoftext|>', 'When', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shop', ',', ' John', ' gave', ' a', ' bottle', ' to']\n",
      "Tokenized answer: [' Mary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.84</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63.98</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m17.84\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m63.98\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.84 Prob: 63.98% Token: | Mary|\n",
      "Top 1th token. Logit: 15.64 Prob:  7.10% Token: | them|\n",
      "Top 2th token. Logit: 15.51 Prob:  6.22% Token: | the|\n",
      "Top 3th token. Logit: 14.92 Prob:  3.46% Token: | his|\n",
      "Top 4th token. Logit: 14.92 Prob:  3.45% Token: | John|\n",
      "Top 5th token. Logit: 13.82 Prob:  1.15% Token: | their|\n",
      "Top 6th token. Logit: 13.76 Prob:  1.08% Token: | her|\n",
      "Top 7th token. Logit: 13.66 Prob:  0.98% Token: | a|\n",
      "Top 8th token. Logit: 13.18 Prob:  0.60% Token: | him|\n",
      "Top 9th token. Logit: 13.06 Prob:  0.54% Token: | Mrs|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test prompt\n",
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    with model.hooks(fwd_hooks = [get_node_patch_hook(l10_att_node, value)]):\n",
    "        metric = metric_fn(model, clean_tokens).item()\n",
    "        print(value, metric)\n",
    "        test_prompt(clean_text, answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import ActivationCache\n",
    "from circuit_finder.core.types import Node, parse_node_name\n",
    "\n",
    "def get_edge_patch_hook(\n",
    "    clean_cache: ActivationCache,\n",
    "    corrupt_cache: ActivationCache,\n",
    "    src_module, # either HookedSAE or HookedTranscoder\n",
    "    src_node: Node,\n",
    "    dest_module, # either HookedSAE or HookedTranscoder\n",
    "    dest_node: Node,\n",
    "):\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try ablating one of the important edges and confirm that the metric goes down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jacob's code \n",
    "def ablation_hook(act, hook, id_to_ablate):\n",
    "    assert hook.name.endswith(\"hook_sae_acts_post\")\n",
    "    act[:, :, id_to_ablate] = 0\n",
    "    return act\n",
    "\n",
    "def patch_hook(act, hook, module, layer, feature_id, patch_pt, scale):\n",
    "    if module == \"mlp\":\n",
    "        decoder_col = mlp_transcoders[layer].W_dec[feature_id, :]\n",
    "    elif module == \"attn\":\n",
    "        decoder_col_concat = attn_saes[layer].W_dec[feature_id, :]\n",
    "        decoder_col = rearrange(\n",
    "            decoder_col_concat, \n",
    "            \"(n_heads d_head -> n_heads d_head)\",\n",
    "            n_heads=model.cfg.n_heads\n",
    "            )\n",
    "    return act + scale*decoder_col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
