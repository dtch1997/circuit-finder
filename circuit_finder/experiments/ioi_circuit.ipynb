{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/home/daniel/ml_workspace/circuit-finder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/ml_workspace/circuit-finder/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from circuit_finder.pretrained import load_model\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283dceadf96f4fafb249a2e5584809d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 26 files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from circuit_finder.pretrained import load_attn_saes, load_hooked_mlp_transcoders\n",
    "from circuit_finder.patching.indirect_leap import preprocess_attn_saes\n",
    "\n",
    "attn_sae_dict = load_attn_saes()\n",
    "attn_sae_dict = preprocess_attn_saes(attn_sae_dict, model)\n",
    "hooked_mlp_transcoder_dict = load_hooked_mlp_transcoders()\n",
    "\n",
    "attn_saes = list(attn_sae_dict.values())\n",
    "transcoders = list(hooked_mlp_transcoder_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"David\"\n",
    "indirect_object = \"Elliot\"\n",
    "\n",
    "clean_text = f\"When {indirect_object} and {subject} went to the shop, {subject} gave a bottle to\"\n",
    "answer = f\" {indirect_object}\"\n",
    "wrong_answer = f\" {subject}\"\n",
    "corrupt_text = \"When Alice and Bob went to the shop, Charlie gave a bottle to\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "clean_tokens = model.to_tokens(clean_text)\n",
    "answer_tokens = model.to_tokens(answer, prepend_bos=False).squeeze(-1)\n",
    "wrong_answer_tokens = model.to_tokens(wrong_answer, prepend_bos=False).squeeze(-1)\n",
    "corrupt_tokens = model.to_tokens(corrupt_text)\n",
    "\n",
    "print(clean_tokens.shape)\n",
    "print(answer_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.717823028564453\n",
      "2.9122209548950195\n",
      "6.478542327880859\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from eindex import eindex\n",
    "from circuit_finder.patching.eap_graph import EAPGraph\n",
    "from circuit_finder.patching.ablate import get_metric_with_ablation\n",
    "from circuit_finder.patching.indirect_leap import IndirectLEAP, LEAPConfig\n",
    "from circuit_finder.utils import clear_memory\n",
    "\n",
    "ablate_tokens = corrupt_tokens\n",
    "\n",
    "def compute_logit_diff(model, clean_tokens, answer_tokens, wrong_answer_tokens):\n",
    "    clean_logits = model(clean_tokens)\n",
    "    last_logits = clean_logits[:, -1, :]\n",
    "    correct_logits = eindex(last_logits, answer_tokens, \"batch [batch]\")\n",
    "    wrong_logits = eindex(last_logits, wrong_answer_tokens, \"batch [batch]\")\n",
    "    return correct_logits - wrong_logits\n",
    "\n",
    "def metric_fn(model, tokens):\n",
    "    logit_diff = compute_logit_diff(model, tokens, answer_tokens, wrong_answer_tokens)\n",
    "    return logit_diff.mean()\n",
    "\n",
    "# NOTE: First, get the ceiling of the patching metric.\n",
    "# TODO: Replace 'last_token_logit' with logit difference\n",
    "with torch.no_grad():\n",
    "    ceiling = metric_fn(model, clean_tokens).item()\n",
    "print(ceiling)\n",
    "\n",
    "# NOTE: Second, get floor of patching metric using empty graph, i.e. ablate everything\n",
    "with torch.no_grad():\n",
    "    empty_graph = EAPGraph([])\n",
    "    floor = get_metric_with_ablation(\n",
    "        model,\n",
    "        empty_graph,\n",
    "        clean_tokens,\n",
    "        metric_fn,\n",
    "        hooked_mlp_transcoder_dict,\n",
    "        attn_sae_dict,\n",
    "        ablate_nodes=\"bm\",\n",
    "        ablate_errors=False,  # Do not ablate errors when running forward pass\n",
    "        first_ablated_layer=2,\n",
    "        corrupt_tokens = ablate_tokens,\n",
    "    ).item()\n",
    "clear_memory()\n",
    "print(floor)\n",
    "\n",
    "\n",
    "# now sweep over thresholds to get graphs with variety of numbers of nodes\n",
    "# for each graph we calculate faithfulness\n",
    "num_nodes_list = []\n",
    "metrics_list = []\n",
    "\n",
    "# Sweep over thresholds\n",
    "# TODO: make configurable\n",
    "# thresholds = [0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1.0]\n",
    "thresholds = [0.06]\n",
    "for threshold in thresholds:\n",
    "    # Setup LEAP algorithm\n",
    "    model.reset_hooks()\n",
    "    cfg = LEAPConfig(threshold=threshold,\n",
    "                    contrast_pairs=False, \n",
    "                    qk_enabled=True,\n",
    "                    chained_attribs=True,\n",
    "                    abs_attribs = False,\n",
    "                    store_error_attribs=True)\n",
    "    leap = IndirectLEAP(\n",
    "        cfg=cfg,\n",
    "        tokens=clean_tokens,\n",
    "        model=model,\n",
    "        metric=metric_fn,\n",
    "        attn_saes=attn_saes,  # type: ignore\n",
    "        transcoders=transcoders,\n",
    "        corrupt_tokens=ablate_tokens,\n",
    "    )\n",
    "\n",
    "    # Populate the graph\n",
    "    leap.run()\n",
    "\n",
    "    # Save the graph\n",
    "    graph = EAPGraph(leap.graph)\n",
    "    error_graph = EAPGraph(leap.error_graph)\n",
    "    num_nodes = len(graph.get_src_nodes())\n",
    "\n",
    "    # # Calculate the metric under ablation\n",
    "    with torch.no_grad():\n",
    "        metric = get_metric_with_ablation(\n",
    "            model,\n",
    "            graph,\n",
    "            clean_tokens,\n",
    "            metric_fn,\n",
    "            hooked_mlp_transcoder_dict,\n",
    "            attn_sae_dict,\n",
    "            ablate_nodes=\"bm\",\n",
    "            ablate_errors=False,\n",
    "            first_ablated_layer=2,\n",
    "            corrupt_tokens = ablate_tokens,\n",
    "        ).item()\n",
    "    clear_memory()\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph.html\n",
      "Generated graph.html. Open this file in Live Server to view the graph.\n"
     ]
    }
   ],
   "source": [
    "from circuit_finder.plotting import make_html_graph\n",
    "\n",
    "# print(len(graph.get_edges()))\n",
    "make_html_graph(leap)\n",
    "\n",
    "del leap\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>23905</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012081</td>\n",
       "      <td>0.062661</td>\n",
       "      <td>0.012081</td>\n",
       "      <td>0.062661</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>7315</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036978</td>\n",
       "      <td>0.199892</td>\n",
       "      <td>0.036978</td>\n",
       "      <td>0.199892</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attn</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>1328</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027274</td>\n",
       "      <td>0.125121</td>\n",
       "      <td>0.027274</td>\n",
       "      <td>0.125121</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attn</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>3093</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043548</td>\n",
       "      <td>0.496754</td>\n",
       "      <td>0.043548</td>\n",
       "      <td>0.496754</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attn</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>4032</td>\n",
       "      <td>metric</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037076</td>\n",
       "      <td>0.174213</td>\n",
       "      <td>0.037076</td>\n",
       "      <td>0.174213</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  src_module_name  src_layer  src_token_idx  src_feature_idx dest_module_name  \\\n",
       "0             mlp          5             14            23905           metric   \n",
       "1             mlp         10             14             7315           metric   \n",
       "2            attn          9             14             1328           metric   \n",
       "3            attn          9             14             3093           metric   \n",
       "4            attn          9             14             4032           metric   \n",
       "\n",
       "   dest_layer  dest_token_idx  dest_feature_idx  edge_metric_attr  \\\n",
       "0          12              14                 0          0.012081   \n",
       "1          12              14                 0          0.036978   \n",
       "2          12              14                 0          0.027274   \n",
       "3          12              14                 0          0.043548   \n",
       "4          12              14                 0          0.037076   \n",
       "\n",
       "   edge_metric_grad  node_node_attr  node_node_grad edge_type  \n",
       "0          0.062661        0.012081        0.062661      None  \n",
       "1          0.199892        0.036978        0.199892      None  \n",
       "2          0.125121        0.027274        0.125121      None  \n",
       "3          0.496754        0.043548        0.496754      None  \n",
       "4          0.174213        0.037076        0.174213      None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the graph to a dataframe\n",
    "\n",
    "import pandas as pd \n",
    "from circuit_finder.core.types import parse_node_name\n",
    "\n",
    "rows = []\n",
    "for edge, edge_info, edge_type in graph.graph:\n",
    "    (dest, src) = edge\n",
    "    if dest == \"null\": continue\n",
    "    (node_node_attr, node_node_grad, edge_metric_attr, edge_metric_grad) = edge_info\n",
    "\n",
    "    src_module_name, src_layer, src_token_idx, src_feature_idx = parse_node_name(src)    \n",
    "    dest_module_name, dest_layer, dest_token_idx, dest_feature_idx = parse_node_name(dest)\n",
    "\n",
    "    rows.append({\n",
    "        \"src_module_name\": src_module_name,\n",
    "        \"src_layer\": src_layer,\n",
    "        \"src_token_idx\": src_token_idx,\n",
    "        \"src_feature_idx\": src_feature_idx,\n",
    "        \"dest_module_name\": dest_module_name,\n",
    "        \"dest_layer\": dest_layer,\n",
    "        \"dest_token_idx\": dest_token_idx,\n",
    "        \"dest_feature_idx\": dest_feature_idx,\n",
    "        \"edge_metric_attr\": edge_metric_attr,\n",
    "        \"edge_metric_grad\": edge_metric_grad,\n",
    "        \"node_node_attr\": node_node_attr,\n",
    "        \"node_node_grad\": node_node_grad,\n",
    "        \"edge_type\": edge_type\n",
    "    }) \n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outgoing_edge_df(\n",
    "    df: pd.DataFrame, \n",
    "    src_module_name: str,\n",
    "    src_layer: int,\n",
    "    src_feature_idx: int,\n",
    "):\n",
    "    return df[\n",
    "        (df[\"src_module_name\"] == src_module_name)\n",
    "        & (df[\"src_layer\"] == src_layer)\n",
    "        & (df[\"src_feature_idx\"] == src_feature_idx)\n",
    "    ]\n",
    "\n",
    "def get_incoming_edge_df(\n",
    "    df: pd.DataFrame, \n",
    "    dest_module_name: str,\n",
    "    dest_layer: int,\n",
    "    dest_feature_idx: int,\n",
    "):\n",
    "    return df[\n",
    "        (df[\"dest_module_name\"] == dest_module_name)\n",
    "        & (df[\"dest_layer\"] == dest_layer)\n",
    "        & (df[\"dest_feature_idx\"] == dest_feature_idx)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [src_module_name, src_layer, src_token_idx, src_feature_idx, dest_module_name, dest_layer, dest_token_idx, dest_feature_idx, edge_metric_attr, edge_metric_grad, node_node_attr, node_node_grad, edge_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upstream edges for layer 6 att 17410\n",
    "\n",
    "get_incoming_edge_df(df, \"attn\", 6, 17410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [src_module_name, src_layer, src_token_idx, src_feature_idx, dest_module_name, dest_layer, dest_token_idx, dest_feature_idx, edge_metric_attr, edge_metric_grad, node_node_attr, node_node_grad, edge_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downstream edges for layer 6 att 17410\n",
    "\n",
    "get_outgoing_edge_df(df, \"attn\", 6, 17410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [src_module_name, src_layer, src_token_idx, src_feature_idx, dest_module_name, dest_layer, dest_token_idx, dest_feature_idx, edge_metric_attr, edge_metric_grad, node_node_attr, node_node_grad, edge_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df = df[\n",
    "    (df[\"src_layer\"] == 8) \n",
    "    & (df[\"src_module_name\"] == \"attn\") \n",
    "    & (df[\"src_feature_idx\"] == 16513)\n",
    "]\n",
    "\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_module_name</th>\n",
       "      <th>src_layer</th>\n",
       "      <th>src_token_idx</th>\n",
       "      <th>src_feature_idx</th>\n",
       "      <th>dest_module_name</th>\n",
       "      <th>dest_layer</th>\n",
       "      <th>dest_token_idx</th>\n",
       "      <th>dest_feature_idx</th>\n",
       "      <th>edge_metric_attr</th>\n",
       "      <th>edge_metric_grad</th>\n",
       "      <th>node_node_attr</th>\n",
       "      <th>node_node_grad</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [src_module_name, src_layer, src_token_idx, src_feature_idx, dest_module_name, dest_layer, dest_token_idx, dest_feature_idx, edge_metric_attr, edge_metric_grad, node_node_attr, node_node_grad, edge_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df = df[\n",
    "    (df[\"src_layer\"] == 10) \n",
    "    & (df[\"src_module_name\"] == \"attn\") \n",
    "    & (df[\"src_feature_idx\"] == 3849)\n",
    "]\n",
    "\n",
    "node_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_finder.core.types import get_node_name\n",
    "\n",
    "l6_att_node = get_node_name(\"attn\", 6, 10, 17410)\n",
    "l8_att_node = get_node_name(\"attn\", 8, 14, 16513)\n",
    "l10_att_node = get_node_name(\"attn\", 10, 14, 3849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the clean and corrupt cache\n",
    "from circuit_finder.patching.ablate import splice_model_with_saes_and_transcoders\n",
    "\n",
    "def filter_sae_acts_and_errors(name: str):\n",
    "    return \"hook_sae_acts_post\" in name or \"hook_sae_error\" in name\n",
    "\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    _, clean_cache = model.run_with_cache(clean_tokens, names_filter = filter_sae_acts_and_errors)\n",
    "    _, corrupt_cache = model.run_with_cache(corrupt_tokens, names_filter = filter_sae_acts_and_errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define some utilities for patching a single node\n",
    "\n",
    "from transformer_lens import ActivationCache\n",
    "from circuit_finder.core.types import Node, parse_node_name\n",
    "\n",
    "def get_act_name(module_name, layer):\n",
    "    if module_name == \"attn\":\n",
    "        return f\"blocks.{layer}.attn.hook_z.hook_sae_acts_post\"\n",
    "    elif module_name == \"mlp\":\n",
    "        return f\"blocks.{layer}.mlp.transcoder.hook_sae_acts_post\"\n",
    "    else:\n",
    "        raise ValueError(module_name)\n",
    "\n",
    "def get_node_act(\n",
    "    cache: ActivationCache,\n",
    "    module_name, layer, token_idx, feature_idx\n",
    "):\n",
    "    act_name = get_act_name(module_name, layer)\n",
    "    return cache[act_name][:, token_idx, feature_idx]\n",
    "\n",
    "def node_patch_hook(act, hook, token_idx, feature_idx, value):\n",
    "    \"\"\" Patches a node by setting its activation to a fixed value. \"\"\"\n",
    "    act[:, token_idx, feature_idx] = value\n",
    "    return act\n",
    "\n",
    "def get_node_patch_hook(\n",
    "    node: Node,\n",
    "    value: float\n",
    "):\n",
    "\n",
    "    module_name, layer, token_idx, feature_idx = parse_node_name(node)\n",
    "    hook_name = get_act_name(module_name, layer)\n",
    "\n",
    "    def hook_fn(act, hook):\n",
    "        return node_patch_hook(act, hook, token_idx, feature_idx, value)\n",
    "    \n",
    "    return hook_name, hook_fn\n",
    "\n",
    "print(get_node_act(clean_cache, \"attn\", 6, 10, 17410))\n",
    "print(get_node_act(corrupt_cache, \"attn\", 6, 10, 17410))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l6_att_feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) \u001b[38;5;28;01mas\u001b[39;00m spliced_model:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks \u001b[38;5;241m=\u001b[39m [get_node_patch_hook(\u001b[43ml6_att_feat\u001b[49m, value)]):\n\u001b[1;32m      5\u001b[0m             metric \u001b[38;5;241m=\u001b[39m metric_fn(model, clean_tokens)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;28mprint\u001b[39m(value, metric)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l6_att_feat' is not defined"
     ]
    }
   ],
   "source": [
    "# Node patching for L6.Att.10.17410\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    for value in range(11):\n",
    "        with model.hooks(fwd_hooks = [get_node_patch_hook(l6_att_feat, value)]):\n",
    "            metric = metric_fn(model, clean_tokens).item()\n",
    "            print(value, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.3522], device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "l8_att_node_info = parse_node_name(l8_att_node)\n",
    "print(get_node_act(clean_cache, *l8_att_node_info))\n",
    "print(get_node_act(corrupt_cache, *l8_att_node_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.6199398040771484\n",
      "1 2.6861095428466797\n",
      "2 2.7564697265625\n",
      "3 2.830913543701172\n",
      "4 2.9091930389404297\n",
      "5 2.990968704223633\n",
      "6 3.0757503509521484\n",
      "7 3.1629371643066406\n",
      "8 3.251924514770508\n",
      "9 3.3420658111572266\n",
      "10 3.432809829711914\n"
     ]
    }
   ],
   "source": [
    "# Node patching for L8.Att.14.16513\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    for value in range(11):\n",
    "        with model.hooks(fwd_hooks = [get_node_patch_hook(l8_att_node, value)]):\n",
    "            metric = metric_fn(model, clean_tokens).item()\n",
    "            print(value, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21.6992], device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "l10_att_node_info = parse_node_name(l10_att_node)\n",
    "print(get_node_act(clean_cache, *l10_att_node_info))\n",
    "print(get_node_act(corrupt_cache, *l10_att_node_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.545804977416992\n",
      "1 2.5825119018554688\n",
      "2 2.619386672973633\n",
      "3 2.6564464569091797\n",
      "4 2.6936283111572266\n",
      "5 2.730976104736328\n",
      "6 2.768484115600586\n",
      "7 2.8061351776123047\n",
      "8 2.843921661376953\n",
      "9 2.8818435668945312\n",
      "10 2.9199295043945312\n"
     ]
    }
   ],
   "source": [
    "# Node patching for L10.Att.14.16513\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    for value in range(11):\n",
    "        with model.hooks(fwd_hooks = [get_node_patch_hook(l10_att_node, value)]):\n",
    "            metric = metric_fn(model, clean_tokens).item()\n",
    "            print(value, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2.9199295043945312\n",
      "Tokenized prompt: ['<|endoftext|>', 'When', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shop', ',', ' John', ' gave', ' a', ' bottle', ' to']\n",
      "Tokenized answer: [' Mary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.84</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63.98</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m17.84\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m63.98\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.84 Prob: 63.98% Token: | Mary|\n",
      "Top 1th token. Logit: 15.64 Prob:  7.10% Token: | them|\n",
      "Top 2th token. Logit: 15.51 Prob:  6.22% Token: | the|\n",
      "Top 3th token. Logit: 14.92 Prob:  3.46% Token: | his|\n",
      "Top 4th token. Logit: 14.92 Prob:  3.45% Token: | John|\n",
      "Top 5th token. Logit: 13.82 Prob:  1.15% Token: | their|\n",
      "Top 6th token. Logit: 13.76 Prob:  1.08% Token: | her|\n",
      "Top 7th token. Logit: 13.66 Prob:  0.98% Token: | a|\n",
      "Top 8th token. Logit: 13.18 Prob:  0.60% Token: | him|\n",
      "Top 9th token. Logit: 13.06 Prob:  0.54% Token: | Mrs|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test prompt\n",
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, attn_saes) as spliced_model:\n",
    "    with model.hooks(fwd_hooks = [get_node_patch_hook(l10_att_node, value)]):\n",
    "        metric = metric_fn(model, clean_tokens).item()\n",
    "        print(value, metric)\n",
    "        test_prompt(clean_text, answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import ActivationCache\n",
    "from circuit_finder.core.types import Node, parse_node_name\n",
    "\n",
    "def get_edge_patch_hook(\n",
    "    clean_cache: ActivationCache,\n",
    "    corrupt_cache: ActivationCache,\n",
    "    src_module, # either HookedSAE or HookedTranscoder\n",
    "    src_node: Node,\n",
    "    dest_module, # either HookedSAE or HookedTranscoder\n",
    "    dest_node: Node,\n",
    "):\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try ablating one of the important edges and confirm that the metric goes down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jacob's code \n",
    "def ablation_hook(act, hook, id_to_ablate):\n",
    "    assert hook.name.endswith(\"hook_sae_acts_post\")\n",
    "    act[:, :, id_to_ablate] = 0\n",
    "    return act\n",
    "\n",
    "def patch_hook(act, hook, module, layer, feature_id, patch_pt, scale):\n",
    "    if module == \"mlp\":\n",
    "        decoder_col = mlp_transcoders[layer].W_dec[feature_id, :]\n",
    "    elif module == \"attn\":\n",
    "        decoder_col_concat = attn_saes[layer].W_dec[feature_id, :]\n",
    "        decoder_col = rearrange(\n",
    "            decoder_col_concat, \n",
    "            \"(n_heads d_head -> n_heads d_head)\",\n",
    "            n_heads=model.cfg.n_heads\n",
    "            )\n",
    "    return act + scale*decoder_col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
