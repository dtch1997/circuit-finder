{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspace/circuit-finder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/circuit-finder/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6987a36e214bbfa2c94ddbed730960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42494e6185384dcc821c571053c89bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5001a429754668a12e64802446faba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db376abfdae4cdaaed8c7d8d6c8e365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8032450e1d664592a3fbb19979939b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e966731370244d8b394284f6a7788cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337d57ca0949469b8fdf2678a6641e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf31575cb9c430b8596171ba9333d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768fb13feaf54a6ab657463165033b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824a6c7517084ca4bd42301902184675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v5_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1da9ff53a043b6a441aaaacba5b553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v5.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492b0c5d3d324020bdb2b0a7149c0482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v4_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd832f7a62e475e85b2d9c90f719460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v4.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f4fb29f6da4766a4928fcee1beb50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a6229c7b2b4a05b4e9ec6b1e3a57d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd100af215f4891a82d9da95970be25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v7_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3a5a8b1d614377b79cc4a8a85a8f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v7.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d7f0f70e1c432b9600bc027fc73181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec97ffdf7a364536ad2a66c6e893fae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a80d9ef25544600ab1172f4b383e57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9c9379ad7c4861a4d3f0d47f5c670d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2094e8db311941d7866b474dc513dd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d800313a051740cfbdf0d37947140734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0264c720652c42b290f691a9ca7cc827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-05_rsanthropic_rie25000_nr4_v6_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99e1a83045445da82a8ed4cbf9224b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-05_rsanthropic_rie25000_nr4_v6.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0db1ba512f24991a44c90b69df5e91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3079cff97dde495286a8ca31cda65c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc434d6e7204f34a657ab0feb8e816b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-05_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c0ab0cbee7491db0cd061f13f0eef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c1.00e-05_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c5ae535f524af4b05d2128042cc8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-06_rsanthropic_rie25000_nr4_v9_cfg.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a03e25dad9e48c2ad12a05437eb0a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c3.16e-06_rsanthropic_rie25000_nr4_v9.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442096af47c846868842d5cad14cddda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 26 files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e4cbb0a0064d04ad5ec0ebdb02ac46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adafd6d5a44474b927a272b6ca1b69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.1.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddea7e4362148c0ac1cc3f01951e7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c1e88be29e43d48cbde859312f7cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.2.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01fafa8e7d5404dbd9f77ccc9fb9d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7761855a05644d1876f46a3d81e7454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.0.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48a802f8a6b4211a2d45af62f834885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89b56370d6a4c16905eeaeaae3e123e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)l_blocks.10.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f494c37319474050b4262e2fd92ede55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)l_blocks.11.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61486f2ab93248e595b0a230a7275452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288275b751604917adb7369dfac2d962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.3.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c00eef971c9405ea213240ba137a1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4bcdf9084f4a4ebf9df1494d2e9931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.4.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3638b985c2434b4a9e14c51831730dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8153a4f1cd594f329b163269aacedf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.5.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f124b08c5486474ea304f502011d3524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1953aeb4ec4e5cb3fd3345b3b773e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.6.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6bbe6d8ed74331b03c1e1265a5bf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cffe7523c2f409da327c1b778c5c9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.7.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf1476d46d54b118c8a52e335ef9ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d75dfb749345d38035aced34705d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.8.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35255c9ed77b4fa38cc36509adccd1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ll_blocks.9.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4c446d7b984d8aaf984eb53a4c5da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ef638daecf4a63acb196ba0d14cbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6c0a9c5fb346efa0d91747a26d28cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)l_blocks.11.ln2.hook_normalized_24576.pt:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fbb37631bc4415b37b9026289d7acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)normalized_24576_log_feature_sparsity.pt:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from circuit_finder.pretrained import (\n",
    "    load_model,\n",
    "    load_attn_saes,\n",
    "    load_hooked_mlp_transcoders,\n",
    ")\n",
    "from circuit_finder.patching.indirect_leap import preprocess_attn_saes\n",
    "\n",
    "model = load_model()\n",
    "attn_saes = load_attn_saes()\n",
    "attn_saes = preprocess_attn_saes(attn_saes, model)\n",
    "hooked_mlp_transcoders = load_hooked_mlp_transcoders()\n",
    "\n",
    "transcoders = list(hooked_mlp_transcoders.values())\n",
    "saes = list(attn_saes.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/circuit-finder/.venv/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for c4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/c4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/root/.cache/huggingface/modules/datasets_modules/datasets/c4/584d57ebe81c209b6c7f31727066d2c4b4bba37cb7092cdd83083d5ec11207db/c4.py:53: FutureWarning: Dataset 'c4' is deprecated and will be deleted. Use 'allenai/c4' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"c4\", \"en\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import ActivationCache\n",
    "from circuit_finder.patching.ablate import (\n",
    "    splice_model_with_saes_and_transcoders,\n",
    "    filter_sae_acts_and_errors,\n",
    ")\n",
    "\n",
    "n_tokens = 0\n",
    "# total_tokens = 100_000 # 100k tokens\n",
    "total_tokens = 100\n",
    "print(f\"Total tokens: {total_tokens}\")\n",
    "\n",
    "# A bit of a hack, run once to get cache shapes\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, saes):\n",
    "    _, dummy_cache = model.run_with_cache(\n",
    "        \"Hello World\", names_filter=filter_sae_acts_and_errors\n",
    "    )\n",
    "\n",
    "\n",
    "zero_cache_dict = {\n",
    "    hook_name: torch.zeros_like(act.sum(1).squeeze(0))\n",
    "    for hook_name, act in dummy_cache.items()\n",
    "}\n",
    "# zero_cache = ActivationCache(zero_cache_dict, model)\n",
    "\n",
    "# Run the model\n",
    "with splice_model_with_saes_and_transcoders(model, transcoders, saes):\n",
    "    for element in dataset[\"train\"]:\n",
    "        text = element[\"text\"]\n",
    "        tokens = model.to_tokens(text)\n",
    "        _, cache = model.run_with_cache(text, names_filter=filter_sae_acts_and_errors)\n",
    "\n",
    "        n_tokens += tokens.shape[1]\n",
    "        for hook_name, act in cache.items():\n",
    "            zero_cache_dict[hook_name] += act.sum(1).squeeze(0)\n",
    "\n",
    "        if n_tokens >= total_tokens:\n",
    "            break\n",
    "\n",
    "# Average the cache\n",
    "for hook_name, act in zero_cache_dict.items():\n",
    "    zero_cache_dict[hook_name] /= n_tokens\n",
    "\n",
    "zero_cache = ActivationCache(zero_cache_dict, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(zero_cache[\"blocks.0.attn.hook_z.hook_sae_acts_post\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.0.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.0.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.0.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.1.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.1.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.1.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.1.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.2.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.2.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.2.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.2.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.3.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.3.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.3.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.3.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.4.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.4.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.4.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.4.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.5.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.5.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.5.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.5.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.6.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.6.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.6.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.6.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.7.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.7.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.7.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.7.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.8.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.8.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.8.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.8.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.9.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.9.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.9.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.9.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.10.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.10.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.10.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.10.mlp.hook_sae_error torch.Size([768])\n",
      "blocks.11.attn.hook_z.hook_sae_acts_post torch.Size([49152])\n",
      "blocks.11.attn.hook_z.hook_sae_error torch.Size([768])\n",
      "blocks.11.mlp.transcoder.hook_sae_acts_post torch.Size([24576])\n",
      "blocks.11.mlp.hook_sae_error torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for hook_name, act in zero_cache.items():\n",
    "    print(hook_name, act.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cache  \n",
    "\n",
    "import pickle\n",
    "with open(\"c4_mean_acts.pkl\", 'wb') as file:\n",
    "    pickle.dump(zero_cache, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Circuit Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/greaterthan_gpt2-small_prompts.json', 'datasets/ioi/ioi_ABBA_template_0_prompts.json', 'datasets/ioi/ioi_ABBA_template_1_prompts.json', 'datasets/ioi/ioi_BABA_template_0_prompts.json', 'datasets/ioi/ioi_BABA_template_1_prompts.json']\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import transformer_lens as tl\n",
    "\n",
    "from simple_parsing import ArgumentParser\n",
    "from dataclasses import dataclass\n",
    "from circuit_finder.patching.eap_graph import EAPGraph\n",
    "from circuit_finder.utils import clear_memory\n",
    "from circuit_finder.patching.ablate import get_metric_with_ablation\n",
    "from circuit_finder.data_loader import load_datasets_from_json, PromptPairBatch\n",
    "from circuit_finder.constants import device\n",
    "from tqdm import tqdm\n",
    "from circuit_finder.patching.ablate import get_metric_with_ablation\n",
    "\n",
    "from typing import Literal\n",
    "from eindex import eindex\n",
    "from pathlib import Path\n",
    "from circuit_finder.pretrained import (\n",
    "    load_model,\n",
    "    load_attn_saes,\n",
    "    load_hooked_mlp_transcoders,\n",
    ")\n",
    "from circuit_finder.patching.indirect_leap import (\n",
    "    preprocess_attn_saes,\n",
    "    IndirectLEAP,\n",
    "    LEAPConfig,\n",
    ")\n",
    "from circuit_finder.core.types import Model\n",
    "from circuit_finder.metrics import batch_avg_answer_diff\n",
    "from circuit_finder.constants import ProjectDir\n",
    "from circuit_finder.patching.ablate import (\n",
    "    splice_model_with_saes_and_transcoders,\n",
    "    get_metric_with_ablation,\n",
    "    AblateType,\n",
    ")\n",
    "\n",
    "from circuit_finder.experiments.run_dataset_sweep import ALL_DATASETS\n",
    "\n",
    "batch_size = 8\n",
    "print(ALL_DATASETS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import ActivationCache\n",
    "from circuit_finder.patching.ablate import (\n",
    "    splice_model_with_saes_and_transcoders,\n",
    "    filter_sae_acts_and_errors,\n",
    ")\n",
    "\n",
    "\n",
    "def get_cache(train_loader):\n",
    "\n",
    "    n_tokens = 0\n",
    "    total_tokens = 100_000 # 100k tokens\n",
    "    # total_tokens = 100\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "\n",
    "    # A bit of a hack, run once to get cache shapes\n",
    "    with splice_model_with_saes_and_transcoders(model, transcoders, saes):\n",
    "        _, dummy_cache = model.run_with_cache(\n",
    "            \"Hello World\", names_filter=filter_sae_acts_and_errors\n",
    "        )\n",
    "\n",
    "\n",
    "    zero_cache_dict = {\n",
    "        hook_name: torch.zeros_like(act.sum(1).squeeze(0))\n",
    "        for hook_name, act in dummy_cache.items()\n",
    "    }\n",
    "    # zero_cache = ActivationCache(zero_cache_dict, model)\n",
    "\n",
    "    # Run the model\n",
    "    with splice_model_with_saes_and_transcoders(model, transcoders, saes):\n",
    "        for batch in train_loader:\n",
    "            tokens = batch.clean\n",
    "            _, cache = model.run_with_cache(tokens, names_filter=filter_sae_acts_and_errors)\n",
    "\n",
    "            n_tokens += tokens.shape[1] * tokens.shape[0]\n",
    "            for hook_name, act in cache.items():\n",
    "                zero_cache_dict[hook_name] += act.sum(1).sum(0)\n",
    "\n",
    "            if n_tokens >= total_tokens:\n",
    "                break\n",
    "\n",
    "    print(n_tokens)\n",
    "\n",
    "    # Average the cache\n",
    "    for hook_name, act in zero_cache_dict.items():\n",
    "        zero_cache_dict[hook_name] /= n_tokens\n",
    "\n",
    "    zero_cache = ActivationCache(zero_cache_dict, model)\n",
    "    return zero_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing datasets/greaterthan_gpt2-small_prompts.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 100000\n",
      "1408\n",
      "Processing datasets/ioi/ioi_ABBA_template_0_prompts.json\n",
      "Total tokens: 100000\n",
      "2048\n",
      "Processing datasets/ioi/ioi_ABBA_template_1_prompts.json\n",
      "Total tokens: 100000\n",
      "2560\n",
      "Processing datasets/ioi/ioi_BABA_template_0_prompts.json\n",
      "Total tokens: 100000\n",
      "2048\n",
      "Processing datasets/ioi/ioi_BABA_template_1_prompts.json\n",
      "Total tokens: 100000\n",
      "2560\n"
     ]
    }
   ],
   "source": [
    "for dataset_path in ALL_DATASETS:\n",
    "    print(\"Processing\", dataset_path)\n",
    "    train_loader, _ = load_datasets_from_json(\n",
    "        model,\n",
    "        ProjectDir / dataset_path,\n",
    "        device=torch.device(\"cuda\"),\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    cache = get_cache(train_loader)\n",
    "    with open(f\"{pathlib.Path(dataset_path).stem}_mean_acts.pkl\", \"wb\") as file:\n",
    "        pickle.dump(zero_cache, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cache\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(f\"{pathlib.Path(dataset_path).stem}_mean_acts.pkl\", \"wb\") as file:\n",
    "    pickle.dump(zero_cache, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
