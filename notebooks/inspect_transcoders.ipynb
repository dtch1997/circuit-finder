{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e22cece7d494baab33bb0468ebeb478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 26 files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageModelSAERunnerConfig(model_name='gpt2-small', hook_point='blocks.8.ln2.hook_normalized', hook_point_layer=8, hook_point_head_index=None, dataset_path='Skylion007/openwebtext', is_dataset_tokenized=False, context_size=128, use_cached_activations=False, cached_activations_path='activations/Skylion007_openwebtext/gpt2-small/blocks.8.ln2.hook_normalized', d_in=768, n_batches_in_buffer=128, total_training_tokens=300000000, store_batch_size=32, device='cuda', seed=42, dtype=torch.float32, is_transcoder=True, out_hook_point='blocks.8.hook_mlp_out', out_hook_point_layer=8, d_out=768, is_sparse_connection=False, sparse_connection_sae_path=None, sparse_connection_l1_coeff=None, sparse_connection_use_W_enc=True, b_dec_init_method='mean', expansion_factor=32, from_pretrained_path=None, l1_coefficient=8e-05, lr=0.0004, lr_scheduler_name='constantwithwarmup', lr_warm_up_steps=5000, train_batch_size=4096, use_ghost_grads=True, feature_sampling_window=1000, feature_sampling_method='Anthropic', resample_batches=32, feature_reinit_scale=0.2, dead_feature_window=5000, dead_feature_estimation_method='no_fire', dead_feature_threshold=1e-06, log_to_wandb=True, wandb_project='gpt2-small-transcoder', wandb_entity='chlenski', wandb_log_frequency=100, n_checkpoints=10, checkpoint_path='checkpoints/pgf0uzku', use_tqdm=True)\n"
     ]
    }
   ],
   "source": [
    "from circuit_finder.pretrained import load_mlp_transcoders\n",
    "\n",
    "transcoder = load_mlp_transcoders([8])[8]\n",
    "print(transcoder.cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: gpt2-small\n",
      "hook_point: blocks.8.ln2.hook_normalized\n",
      "hook_point_layer: 8\n",
      "hook_point_head_index: None\n",
      "dataset_path: Skylion007/openwebtext\n",
      "is_dataset_tokenized: False\n",
      "context_size: 128\n",
      "use_cached_activations: False\n",
      "cached_activations_path: activations/Skylion007_openwebtext/gpt2-small/blocks.8.ln2.hook_normalized\n",
      "d_in: 768\n",
      "n_batches_in_buffer: 128\n",
      "total_training_tokens: 300000000\n",
      "store_batch_size: 32\n",
      "device: cuda\n",
      "seed: 42\n",
      "dtype: torch.float32\n",
      "is_transcoder: True\n",
      "out_hook_point: blocks.8.hook_mlp_out\n",
      "out_hook_point_layer: 8\n",
      "d_out: 768\n",
      "is_sparse_connection: False\n",
      "sparse_connection_sae_path: None\n",
      "sparse_connection_l1_coeff: None\n",
      "sparse_connection_use_W_enc: True\n",
      "b_dec_init_method: mean\n",
      "expansion_factor: 32\n",
      "from_pretrained_path: None\n",
      "l1_coefficient: 8e-05\n",
      "lr: 0.0004\n",
      "lr_scheduler_name: constantwithwarmup\n",
      "lr_warm_up_steps: 5000\n",
      "train_batch_size: 4096\n",
      "use_ghost_grads: True\n",
      "feature_sampling_window: 1000\n",
      "feature_sampling_method: Anthropic\n",
      "resample_batches: 32\n",
      "feature_reinit_scale: 0.2\n",
      "dead_feature_window: 5000\n",
      "dead_feature_estimation_method: no_fire\n",
      "dead_feature_threshold: 1e-06\n",
      "log_to_wandb: True\n",
      "wandb_project: gpt2-small-transcoder\n",
      "wandb_entity: chlenski\n",
      "wandb_log_frequency: 100\n",
      "n_checkpoints: 10\n",
      "checkpoint_path: checkpoints/pgf0uzku\n",
      "use_tqdm: True\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "for key, value in asdict(transcoder.cfg).items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_finder.pretrained import load_model\n",
    "\n",
    "model = load_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(3.7746, device='cuda:0'), ActivationCache with keys ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.hook_attn_in', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.attn.hook_result', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.hook_mlp_in', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.hook_attn_in', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.attn.hook_result', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.hook_mlp_in', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.hook_attn_in', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.attn.hook_result', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.hook_mlp_in', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.hook_attn_in', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.attn.hook_result', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.hook_mlp_in', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.hook_attn_in', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.attn.hook_result', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.hook_mlp_in', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.hook_attn_in', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.attn.hook_result', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.hook_mlp_in', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.hook_attn_in', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.attn.hook_result', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.hook_mlp_in', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.hook_attn_in', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.attn.hook_result', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.hook_mlp_in', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.hook_attn_in', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.attn.hook_result', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.hook_mlp_in', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.hook_attn_in', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.attn.hook_result', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.hook_mlp_in', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.hook_attn_in', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.attn.hook_result', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.hook_mlp_in', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.hook_attn_in', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.attn.hook_result', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.hook_mlp_in', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])\n",
      "tensor(3.7866, device='cuda:0', grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from circuit_finder.patching.transcoder_replacement_ctx import (\n",
    "    TranscoderReplacementContext,\n",
    ")\n",
    "\n",
    "text = \"When John and Mary went to the shops, John gave a bottle to Mary\"\n",
    "\n",
    "orig_loss = model.run_with_cache(text, return_type=\"loss\")\n",
    "print(orig_loss)\n",
    "\n",
    "with TranscoderReplacementContext(model, [transcoder]):\n",
    "    loss, _ = model.run_with_cache(text, return_type=\"loss\")\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a08a5c84f224ae1b0906dcf552d7540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 26 files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1620, device='cuda:0', grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "transcoders = load_mlp_transcoders()\n",
    "with TranscoderReplacementContext(model, list(transcoders.values())):\n",
    "    loss, _ = model.run_with_cache(text, return_type=\"loss\")\n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
